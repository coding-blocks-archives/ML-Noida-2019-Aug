{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "from keras.layers import Embedding, Input, Dense, SimpleRNN\n",
    "\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "((X_train, y_train), (X_test, y_test)) = imdb.load_data(num_words=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = imdb.get_word_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_mod = sequence.pad_sequences(X_train, 400)\n",
    "X_test_mod = sequence.pad_sequences(X_test, 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 0, 1, 0])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_layer = Input(shape=(400,))\n",
    "emb = Embedding(5000, 100)(in_layer)\n",
    "rnn = SimpleRNN(64, dropout=.05, recurrent_dropout=.05)(emb)\n",
    "d2 = Dense(10, activation=\"tanh\")(rnn)\n",
    "d3 = Dense(1, activation=\"sigmoid\")(d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(in_layer, d3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "25000/25000 [==============================] - 26s 1ms/step - loss: 0.6558 - accuracy: 0.6030\n",
      "Epoch 2/5\n",
      "25000/25000 [==============================] - 25s 1ms/step - loss: 0.4795 - accuracy: 0.7771\n",
      "Epoch 3/5\n",
      "25000/25000 [==============================] - 25s 1ms/step - loss: 0.3948 - accuracy: 0.8268\n",
      "Epoch 4/5\n",
      "25000/25000 [==============================] - 26s 1ms/step - loss: 0.3378 - accuracy: 0.8583\n",
      "Epoch 5/5\n",
      "25000/25000 [==============================] - 26s 1ms/step - loss: 0.3189 - accuracy: 0.8686\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x136827ef0>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_mod, y_train.reshape(-1, 1), epochs=5,batch_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 30s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4206490128946304, 0.8223999738693237]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_mod, y_test.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = \"\"\"You want to do something really neat? Take the movie \"Pulp Fiction\" and re-cut it, so that, instead of being out of sequence, it is actually in proper sequence. It can be done. Why do this? Because if you do, you will see what a nothing movie this really is. There is no central plot, there is no real theme, or story or climax. It is just a bunch of tricks and overly snappy dialog, masquerading a piece of fluff that has as much depth as the kiddie pool. Hey, more power to Tarantino, the guy is a Houdini, full of slight of hand. But are we really so simple, that we are ranking this one of the ten greatest movies ever made? Come on! OK, I know that Travolta is cool and Jackson is funny. However, let's reserve the greatest films of all-time category for real masterpieces and real stories, and not some overly slick pulp geared towards video store geeks.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8370669]], dtype=float32)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "words = word_tokenize(sent)\n",
    "li = []\n",
    "for word in words:\n",
    "    if word in vocab and vocab[word] < 5000:\n",
    "        li.append(vocab[word])\n",
    "out = sequence.pad_sequences([li], 400)\n",
    "model.predict(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
